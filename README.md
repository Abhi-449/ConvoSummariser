# ConvoSummariser
ConvoSummarizer is a Retrieval-Augmented Generation (RAG) chatbot that can ingest documents (PDF, TXT, EML), build embeddings, and answer user questions about them. Built with LangChain, HuggingFace Transformers, FAISS, and Streamlit, itâ€™s designed as a modular prototype that runs on a local machine (even on modest GPUs like RTX 3050).

ğŸš€ Features

ğŸ“‚ Upload documents directly (PDF, TXT, EML).

ğŸ” Automatic ingestion + text chunking.

ğŸ§  Embeddings with FAISS vector search.

ğŸ¤– Question answering using HuggingFace LLMs (Flan-T5).

ğŸ›ï¸ Streamlit interface with file upload + chatbot.

âš¡ Runs locally with no paid API keys required.

ğŸ› ï¸ Tech Stack

LangChain â†’ document loaders, RAG pipeline.

HuggingFace Transformers â†’ Flan-T5 model for text generation.

FAISS â†’ vectorstore for retrieval.

Streamlit â†’ frontend for chatbot + file upload.

Python â†’ core backend services.

ğŸ“‚ Project Structure
Convosummarizer/
â”‚â”€â”€ app.py                  # Streamlit UI
â”‚â”€â”€ ingestion_service.py    # File ingestion + chunking
â”‚â”€â”€ embedding_service.py    # Embedding + FAISS index
â”‚â”€â”€ llm_service.py          # HuggingFace LLM loader
â”‚â”€â”€ rag_service.py          # RAG chain builder
â”‚â”€â”€ data/                   # Sample documents
â”‚â”€â”€ requirements.txt        # Dependencies

âš¡ Quickstart

Clone the repo

git clone https://github.com/<your-username>/Convosummarizer.git
cd Convosummarizer


Create virtual environment

conda create -n convosummarizer python=3.10 -y
conda activate convosummarizer


Install dependencies

pip install -r requirements.txt


Run the app

streamlit run app.py


Upload files & chat

Drop in your .pdf, .txt, or .eml files.

Ask questions â†’ get answers from your documents.

ğŸ“Œ Roadmap

 Add conversation memory (multi-turn chats).

 Chat-style UI with st.chat_message.

 Persistent vectorstore (save embeddings across sessions).

 Deploy frontend in React for multi-tech stack showcase.
